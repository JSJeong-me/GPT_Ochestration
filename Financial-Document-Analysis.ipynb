{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM8xKf0clCNkqOwrQEPk56a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT_Ochestration/blob/main/Financial-Document-Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIqgnJSozSLO",
        "outputId": "5973e9af-9a13-4bad-ebb7-8be6f6e6019b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.2.3-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index pypdf"
      ],
      "metadata": {
        "id": "75LSbSXRzxVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVHiFko70bq5",
        "outputId": "5a94ad9c-5403-46b0-a037-3925015e5689"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Variables\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY', 'sk-')"
      ],
      "metadata": {
        "id": "ZvzUGusV0UKc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up the OpenAI API client\n",
        "openai.api_key = \"sk-\""
      ],
      "metadata": {
        "id": "HzaLTWds1gxx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "# print(OpenAI_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaTXN5ZK2Qt-",
        "outputId": "a7169bbb-22ef-435b-b32c-4f7628d4d61b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENAI_API_KEY=\"sk-\"\n",
        "# openai.api_key=OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "QgRtzHrb3dE1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai | grep Version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y1DANFG0tJi",
        "outputId": "4bf71e95-f72e-448b-9e95-20ee041b1b68"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "\n",
        "from llama_index import SimpleDirectoryReader, ServiceContext, VectorStoreIndex\n",
        "from llama_index import set_global_service_context\n",
        "from llama_index.response.pprint_utils import pprint_response\n",
        "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.query_engine import SubQuestionQueryEngine"
      ],
      "metadata": {
        "id": "fszJw-ce0xj1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=-1)\n",
        "llm = OpenAI(temperature=0, model_name=\"text-davinci-003\", max_tokens=-1, openai_api_key=\"sk-\")\n"
      ],
      "metadata": {
        "id": "rnjJsiDP07-z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(llm=llm)\n",
        "set_global_service_context(service_context=service_context)"
      ],
      "metadata": {
        "id": "kjklIz1E4T7G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyft_docs = SimpleDirectoryReader(input_files=[\"S-ECOPRO-20230814.pdf\"]).load_data()\n",
        "uber_docs = SimpleDirectoryReader(input_files=[\"S-INTERROJO-20230814.pdf\"]).load_data()"
      ],
      "metadata": {
        "id": "p6Grt6eX5WB_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Loaded lyft 10-K with {len(lyft_docs)} pages')\n",
        "print(f'Loaded Uber 10-K with {len(uber_docs)} pages')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amdx_uFq5hwo",
        "outputId": "a3b92a40-fb29-4c97-a0f6-b716056efb38"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded lyft 10-K with 19 pages\n",
            "Loaded Uber 10-K with 20 pages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
        "uber_index = VectorStoreIndex.from_documents(uber_docs)"
      ],
      "metadata": {
        "id": "BQtN5-Ql5mtu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "VDpLB59j5q06"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
      ],
      "metadata": {
        "id": "O6JRf9ja5snE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = await lyft_engine.aquery('What is the summay of company in 2023?')"
      ],
      "metadata": {
        "id": "MQQYoSQ45vnl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flqikfB38CJC",
        "outputId": "2b1c776c-baa5-445f-b43a-3cca5b980dbe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " In 2023, the company changed its business purpose through the 6th regular shareholders' meeting on March 29th and the temporary shareholders' meeting on June 15th. The company also issued additional shares due to stock dividends and convertible bonds, resulting in a total of 30,453,901 shares issued.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = await uber_engine.aquery('What is the summary of company in 2021?')"
      ],
      "metadata": {
        "id": "1K4Rix128tSO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PgFbEsb89qA",
        "outputId": "33242f7b-3efb-4ce0-cb8a-46fbe8a4fdec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " In 2021, the company secured the source technology for smart contact lenses that can help with the diagnosis and management of diseases such as diabetes and glaucoma through its 'World Class 300' project. The company is also pursuing the commercialization of pressure measurement smart contact lenses through its 'Nano Convergence 2020+' project, which is being conducted through its subsidiary Optroth.\n"
          ]
        }
      ]
    }
  ]
}