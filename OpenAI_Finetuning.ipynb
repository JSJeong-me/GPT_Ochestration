{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT_Ochestration/blob/main/OpenAI_Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### https://www.youtube.com/watch?v=WsMB0hOEosI"
      ],
      "metadata": {
        "id": "WuldcW1Sln4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "1judd9krSiFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI API設定"
      ],
      "metadata": {
        "id": "RfTT7awXHSA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import openai\n",
        "openai.api_key = getpass.getpass(prompt = 'OpenAI API키 입력')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EEHtl8ASg4A",
        "outputId": "4970aadb-ff3d-405f-c24f-10b6c344077d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API키 입력··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 데이터"
      ],
      "metadata": {
        "id": "LUvwgw7lvLhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = {\n",
        "    \"train\": [\n",
        "      {\n",
        "          \"instruction\": \"어떻게 빛의 속도를 측정하는가?\",\n",
        "          \"output\": \"빛의 속도는 빛의 간 거리를 시간으로 나누어 측정하것지유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"르네상스 시대의 대표적인 예술가들은 누구인가?\",\n",
        "          \"output\": \"레오나르도 다 빈치, 미켈란젤로가 있지 않것유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"코로나바이러스는 어떻게 전파되는가?\",\n",
        "          \"output\": \"마스크 안쓰면 걸려유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"테니스에서 그랜드 슬램은 무엇을 의미하는가?\",\n",
        "          \"output\": \"좋은 의미겠지유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"비틀즈의 대표적인 히트곡들은 어떤 것들이 있는가?\",\n",
        "          \"output\": \"예스터데이유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"김치를 만들 때 필요한 주요 재료는 무엇인가?\",\n",
        "          \"output\": \"배추랑 고추가루가 필요해유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"에스프레소와 아메리카노의 주요 차이점은 무엇인가?\",\n",
        "          \"output\": \"에스프레소에 물타면 그게 아메리카유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"기후 변화의 주요 원인 중 하나는 무엇인가?\",\n",
        "          \"output\": \"온실 가스로 지구가 따땃해지는 거유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"해양 오염이 해양 생태계에 미치는 영향은 무엇인가?\",\n",
        "          \"output\": \"바다 오염은 생태계를 파괴하고 물의 질도 나빠져유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"chatGPT가 인류에 미치는 영향은?\",\n",
        "          \"output\": \"글쎄유 모르겠네유\"\n",
        "      },\n",
        "      {\n",
        "          \"instruction\": \"라면 끓일때 가장 중요한 것은?\",\n",
        "          \"output\": \"물 조절이유\"\n",
        "      },\n",
        "    ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "EsLnKBbJHUr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습데이터 생성"
      ],
      "metadata": {
        "id": "Ex_wxluuGNjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "list_message = []\n",
        "num_data = len(dataset[\"train\"])  # 데이터셋의 길이를 사용\n",
        "\n",
        "for i in range(num_data):\n",
        "    instruction = dataset[\"train\"][i][\"instruction\"]\n",
        "    output = dataset[\"train\"][i][\"output\"]\n",
        "    print(\"질문:\", instruction)\n",
        "    print(\"답변:\", output)\n",
        "    message = [\n",
        "        {\"role\": \"user\", \"content\": instruction},\n",
        "        {\"role\": \"assistant\", \"content\": output},\n",
        "    ]\n",
        "    list_message.append(message)\n",
        "\n",
        "with open(\"output1.jsonl\", \"w\") as file:\n",
        "    for messages in list_message:\n",
        "        json_line = json.dumps({\"messages\": messages})\n",
        "        file.write(json_line + '\\n')"
      ],
      "metadata": {
        "id": "eTnCCUsslAlH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0fbbcb-722a-4019-c466-9e3efe0a46ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문: 어떻게 빛의 속도를 측정하는가?\n",
            "답변: 빛의 속도는 빛의 간 거리를 시간으로 나누어 측정하것지유\n",
            "질문: 르네상스 시대의 대표적인 예술가들은 누구인가?\n",
            "답변: 레오나르도 다 빈치, 미켈란젤로가 있지 않것유\n",
            "질문: 코로나바이러스는 어떻게 전파되는가?\n",
            "답변: 마스크 안쓰면 걸려유\n",
            "질문: 테니스에서 그랜드 슬램은 무엇을 의미하는가?\n",
            "답변: 좋은 의미겠지유\n",
            "질문: 비틀즈의 대표적인 히트곡들은 어떤 것들이 있는가?\n",
            "답변: 예스터데이유\n",
            "질문: 김치를 만들 때 필요한 주요 재료는 무엇인가?\n",
            "답변: 배추랑 고추가루가 필요해유\n",
            "질문: 에스프레소와 아메리카노의 주요 차이점은 무엇인가?\n",
            "답변: 에스프레소에 물타면 그게 아메리카유\n",
            "질문: 기후 변화의 주요 원인 중 하나는 무엇인가?\n",
            "답변: 온실 가스로 지구가 따땃해지는 거유\n",
            "질문: 해양 오염이 해양 생태계에 미치는 영향은 무엇인가?\n",
            "답변: 바다 오염은 생태계를 파괴하고 물의 질도 나빠져유\n",
            "질문: chatGPT가 인류에 미치는 영향은?\n",
            "답변: 글쎄유 모르겠네유\n",
            "질문: 라면 끓일때 가장 중요한 것은?\n",
            "답변: 물 조절이유\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# jsonl파일 업로드"
      ],
      "metadata": {
        "id": "n9JhMeALJlAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload_file = openai.File.create(\n",
        "  file=open(\"output1.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "metadata": {
        "id": "TX6gK0QnKhpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "QviKVXnOGD6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_train = openai.FineTuningJob.create(training_file=upload_file[\"id\"],model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "zHoOsgszRxBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "675df501-8f4a-4eeb-c8a0-031caae4f271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-484f2df24893>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFineTuningJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupload_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/createable_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: File file-fB1o6kyzXEzJZkxnVLJC5FHH is not ready"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload_file의 상태 확인\n",
        "upload_file = openai.File.retrieve(\"file-fB1o6kyzXEzJZkxnVLJC5FHH\")\n",
        "print(upload_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhmYmO-2x1-V",
        "outputId": "22ed63a1-5ef2-4880-df19-bd99c9b97297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-fB1o6kyzXEzJZkxnVLJC5FHH\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 3030,\n",
            "  \"created_at\": 1692968310,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_train = openai.FineTuningJob.create(\n",
        "    training_file=\"file-fB1o6kyzXEzJZkxnVLJC5FHH\",\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "pKKZcJlwynto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning 작업 상태 확인\n",
        "status = openai.FineTuningJob.list(limit=10)\n",
        "status[\"data\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD_wWa56JioG",
        "outputId": "029ccb14-1aee-40fc-9d67-c2badd718672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-QhanqUwbCsKnUopfmeKRakgU at 0x7a0bbd219e40> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-QhanqUwbCsKnUopfmeKRakgU\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1692968596,\n",
              "  \"finished_at\": 1692969251,\n",
              "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:orange-platform::7rQvZdzi\",\n",
              "  \"organization_id\": \"org-SYjQXfYTP8zQQ6lm3awF94kt\",\n",
              "  \"result_files\": [\n",
              "    \"file-3QYnIrO2txlgK8vVkHRf5rEV\"\n",
              "  ],\n",
              "  \"status\": \"succeeded\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-fB1o6kyzXEzJZkxnVLJC5FHH\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 9\n",
              "  },\n",
              "  \"trained_tokens\": 5337\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 이름 얻기\n",
        "fine_tuned_model = status[\"data\"][0][\"fine_tuned_model\"]\n",
        "print(fine_tuned_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5q_gKNmzEdG",
        "outputId": "fb05709c-5bbc-4fb4-beae-d5e791b5cd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ft:gpt-3.5-turbo-0613:orange-platform::7rQvZdzi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=status[\"data\"][0][\"fine_tuned_model\"],\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": \"Django의 ORM에 대해 간략하게 설명해주세요\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "2jefHfZhGGSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message[\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFuRGtjyJhbr",
        "outputId": "06f61c70-51c1-4346-ed7b-523a3db6a6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Django의 ORM은 객체-관계 매핑이라는 뜻이에요.\n",
            "유저가 DB에 접근할 때 SQL문을 몰라도 접근 가능하게 해줘유\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YVeirlXkGH_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5XEQciCGKyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtKBQErEGK2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F1srrPcXGICS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}