{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT_Ochestration/blob/main/02_lcel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc925562",
      "metadata": {
        "id": "fc925562"
      },
      "source": [
        "# LangChain Expression Language (LCEL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install python-dotenv\n",
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "tCkciVlzEBkd"
      },
      "id": "tCkciVlzEBkd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "q1ngMhSuEH1o"
      },
      "id": "q1ngMhSuEH1o",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "044db1b7-c18c-45d2-be7a-29f027c901e2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2de9d2bd-18de-44d5-81ac-5918e2106367",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2de9d2bd-18de-44d5-81ac-5918e2106367",
        "outputId": "0aa72e12-f7ab-4c60-878a-022678baa6a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic==1.10.8\n",
            "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.8) (4.9.0)\n",
            "Installing collected packages: pydantic\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.1\n",
            "    Uninstalling pydantic-2.6.1:\n",
            "      Successfully uninstalled pydantic-2.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pydantic-1.10.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic==1.10.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e",
      "metadata": {
        "height": 64,
        "id": "fd55c0a0-ca4e-4311-a33c-fcebeb7d8b1e"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
      "metadata": {
        "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740"
      },
      "source": [
        "## Simple Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6a0be20d-0e00-478c-a844-017cad13af22",
      "metadata": {
        "height": 98,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a0be20d-0e00-478c-a844-017cad13af22",
        "outputId": "43addb86-3f76-473f-af2f-e3a3943a7c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"tell me a short joke about {topic}\"\n",
        ")\n",
        "model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b",
      "metadata": {
        "height": 30,
        "id": "aedf1c1e-b697-47ce-9d81-eaec9192243b"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "6df32028-d35f-4392-bb15-ddeec9ee09b5",
        "outputId": "b9bc567c-6d8e-4886-a821-65b9f2f75d3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship anymore!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
      "metadata": {
        "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a"
      },
      "source": [
        "## More complex chain\n",
        "\n",
        "And Runnable Map to supply user-provided inputs to the prompt."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docarray\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPRI0YN3GTIQ",
        "outputId": "86163792-6c9a-4d06-bba2-e99f3d41d03b"
      },
      "id": "OPRI0YN3GTIQ",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docarray in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.25.2)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray) (3.9.14)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.10.8)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (13.7.0)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.10/dist-packages (from docarray) (2.31.0.20240218)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->docarray) (4.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (2.16.1)\n",
            "Requirement already satisfied: urllib3>=2 in /usr/local/lib/python3.10/dist-packages (from types-requests>=2.28.11.6->docarray) (2.0.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9",
      "metadata": {
        "height": 47,
        "id": "d036bb8e-8ca7-4dbd-8103-f50a3c8c3af9"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DocArrayInMemorySearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702",
      "metadata": {
        "height": 98,
        "id": "8955cff7-f1a2-4f94-ab5b-fcdda0859702"
      },
      "outputs": [],
      "source": [
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
        "    embedding=OpenAIEmbeddings()\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2df87934-1697-405c-b460-5e9bfd16c792",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2df87934-1697-405c-b460-5e9bfd16c792",
        "outputId": "9f58ac20-a505-4379-967a-454b44d54678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='harrison worked at kensho'),\n",
              " Document(page_content='bears like to eat honey')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"where did harrison work?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
        "outputId": "b93d66d3-c5ca-4bf0-a451-35947f65d30b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='bears like to eat honey'),\n",
              " Document(page_content='harrison worked at kensho')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"what do bears like to eat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
      "metadata": {
        "height": 116,
        "id": "127a7fb6-5821-4934-ab56-9e3300516c05"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
      "metadata": {
        "height": 31,
        "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnableMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc",
      "metadata": {
        "height": 103,
        "id": "a9ca6506-826f-4420-8f19-25dd4dbbc1dc"
      },
      "outputs": [],
      "source": [
        "chain = RunnableMap({\n",
        "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "}) | prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "707d1319-8840-4ed5-b4a4-a2a128799db6",
        "outputId": "09e18164-cadf-4186-ed7a-1f902b7c437c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Harrison worked at Kensho.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"where did harrison work?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "05ec3727-4284-417e-9e23-eec0682eb002",
      "metadata": {
        "height": 103,
        "id": "05ec3727-4284-417e-9e23-eec0682eb002"
      },
      "outputs": [],
      "source": [
        "inputs = RunnableMap({\n",
        "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4216c7ab-6d1b-4f2a-98dc-5d2ace23e3c2",
        "outputId": "ab9d8e76-d44d-4ade-d1c0-4fb3586b759d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(page_content='harrison worked at kensho'),\n",
              "  Document(page_content='bears like to eat honey')],\n",
              " 'question': 'where did harrison work?'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "inputs.invoke({\"question\": \"where did harrison work?\"})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = inputs.invoke({\"question\": \"where did harrison work?\"})"
      ],
      "metadata": {
        "id": "_j-VGTuPGzv-"
      },
      "id": "_j-VGTuPGzv-",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response[\"context\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83XAbZfVG6-7",
        "outputId": "83815fb2-0e34-489b-fc6c-648a30beb8f1"
      },
      "id": "83XAbZfVG6-7",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='harrison worked at kensho')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
      "metadata": {
        "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863"
      },
      "source": [
        "## Bind\n",
        "\n",
        "and OpenAI Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
      "metadata": {
        "height": 286,
        "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "      \"name\": \"weather_search\",\n",
        "      \"description\": \"Search for weather given an airport code\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"airport_code\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The airport code to get the weather for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "      }\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5",
      "metadata": {
        "height": 116,
        "id": "f8be4721-91d2-4ae6-8fdb-e91dc6ac1bc5"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
      "metadata": {
        "height": 31,
        "id": "e61b095d-9934-41b8-a794-a9dd57e9c733"
      },
      "outputs": [],
      "source": [
        "runnable = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
        "outputId": "9a9cdd01-6c32-4a2a-e7d3-1acc94d777a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'weather_search', 'arguments': '{\"airport_code\":\"SFO\"}'}})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "runnable.invoke({\"input\": \"what is the weather in sf\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "3a22faf5-ea24-48d2-b028-03733b548225",
      "metadata": {
        "height": 524,
        "id": "3a22faf5-ea24-48d2-b028-03733b548225"
      },
      "outputs": [],
      "source": [
        "functions = [\n",
        "    {\n",
        "      \"name\": \"weather_search\",\n",
        "      \"description\": \"Search for weather given an airport code\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"airport_code\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The airport code to get the weather for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "      }\n",
        "    },\n",
        "        {\n",
        "      \"name\": \"sports_search\",\n",
        "      \"description\": \"Search for news of recent sport events\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"team_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The sports team to search for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"team_name\"]\n",
        "      }\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef",
      "metadata": {
        "height": 31,
        "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef"
      },
      "outputs": [],
      "source": [
        "model = model.bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567",
      "metadata": {
        "height": 31,
        "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567"
      },
      "outputs": [],
      "source": [
        "runnable = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
        "outputId": "7fba9d1d-c474-4e20-d74b-06233391715b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'name': 'sports_search', 'arguments': '{\"team_name\":\"patriots\"}'}})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
      "metadata": {
        "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a"
      },
      "source": [
        "## Fallbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
      "metadata": {
        "height": 48,
        "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef73d77-9cac-419a-9583-8aefc6c9277b",
      "metadata": {
        "id": "bef73d77-9cac-419a-9583-8aefc6c9277b"
      },
      "source": [
        "**Note**: Due to the deprecation of OpenAI's model `text-davinci-001` on 4 January 2024, you'll be using OpenAI's recommended replacement model `gpt-3.5-turbo-instruct` instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
      "metadata": {
        "height": 116,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
        "outputId": "88836881-48bb-4da6-81bf-723b1800d31d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "simple_model = OpenAI(\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        "    model=\"gpt-3.5-turbo-instruct\"\n",
        ")\n",
        "simple_chain = simple_model | json.loads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
      "metadata": {
        "height": 52,
        "id": "441928c5-8712-45c5-bfdf-6f51634198a7"
      },
      "outputs": [],
      "source": [
        "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "0739e85f-8497-4471-8ec9-17e958d80771",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0739e85f-8497-4471-8ec9-17e958d80771",
        "outputId": "5185f8bb-721b-47c9-8da8-78423d81ac5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n{\\n    \"title\": \"Autumn Leaves\",\\n    \"author\": \"Emily Dickinson\",\\n    \"first_line\": \"The leaves are falling, one by one\"\\n}\\n\\n{\\n    \"title\": \"The Ocean\\'s Song\",\\n    \"author\": \"Pablo Neruda\",\\n    \"first_line\": \"I hear the ocean\\'s song, a symphony of waves\"\\n}\\n\\n{\\n    \"title\": \"A Winter\\'s Night\",\\n    \"author\": \"Robert Frost\",\\n    \"first_line\": \"The snow falls softly, covering the ground\"\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "simple_model.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
      "metadata": {
        "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219"
      },
      "source": [
        "**Note**: The next line is expected to fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "2a5e8492-0927-4a3a-b939-947826246330",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2a5e8492-0927-4a3a-b939-947826246330",
        "outputId": "9ee14365-bfcb-4d90-f92d-b88a3619eab6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Extra data: line 9 column 1 (char 125)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7b2363c45b31>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   2054\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3505\u001b[0m         \u001b[0;34m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3507\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   3508\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             output = cast(\n\u001b[1;32m   1245\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1247\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3381\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3383\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   3384\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extra data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 9 column 1 (char 125)"
          ]
        }
      ],
      "source": [
        "simple_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
      "metadata": {
        "height": 48,
        "id": "6814143b-4a35-4d29-bd32-ba461274bcbf"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(temperature=0)\n",
        "chain = model | StrOutputParser() | json.loads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
        "outputId": "07a098f1-5b30-42d1-9af8-ded4979d70e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'poem1': {'title': 'The Night Sky',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'The night is starry and the stars are blue.'},\n",
              " 'poem2': {'title': 'Autumn Leaves',\n",
              "  'author': 'Robert Frost',\n",
              "  'firstLine': \"Nature's first green is gold,\"},\n",
              " 'poem3': {'title': 'A Dream Within a Dream',\n",
              "  'author': 'Edgar Allan Poe',\n",
              "  'firstLine': 'Take this kiss upon the brow!'}}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
      "metadata": {
        "height": 31,
        "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48"
      },
      "outputs": [],
      "source": [
        "final_chain = simple_chain.with_fallbacks([chain])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
        "outputId": "b8a84c7d-531f-450d-8711-7e12ccc91f43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'poem1': {'title': 'The Rose',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'A rose is a rose is a rose'},\n",
              " 'poem2': {'title': 'The Road Not Taken',\n",
              "  'author': 'Robert Frost',\n",
              "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
              " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
              "  'author': 'Emily Dickinson',\n",
              "  'firstLine': 'Hope is the thing with feathers'}}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "final_chain.invoke(challenge)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
      "metadata": {
        "id": "3fcfdda0-3db2-4073-a647-f2d62c460349"
      },
      "source": [
        "## Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
      "metadata": {
        "height": 133,
        "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a short joke about {topic}\"\n",
        ")\n",
        "model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
        "outputId": "f307aee8-13ed-4efb-9252-4335a0ee80a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the bear break up with his girlfriend? \\nBecause she was unbearable!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "chain.invoke({\"topic\": \"bears\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
      "metadata": {
        "height": 31,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
        "outputId": "e9d9a8a7-8d37-499f-827e-a53b40c404e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship any longer!\",\n",
              " 'Why are frogs so happy? Because they eat whatever bugs them!']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
      "metadata": {
        "height": 48,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
        "outputId": "4c87abb9-8b23-4c2e-a03f-8d2d2f325b30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Why\n",
            " do\n",
            " bears\n",
            " have\n",
            " hairy\n",
            " coats\n",
            "?\n",
            "\n",
            "\n",
            "F\n",
            "ur\n",
            " protection\n",
            "!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for t in chain.stream({\"topic\": \"bears\"}):\n",
        "    print(t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
      "metadata": {
        "height": 48,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
        "outputId": "aa4870b6-89b7-4acc-ad47-b0f756fcc1e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the relationship anymore!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3082379-f75e-4a74-bee5-c18ddc5ac4dc",
      "metadata": {
        "height": 31,
        "id": "f3082379-f75e-4a74-bee5-c18ddc5ac4dc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adccca48-787e-4219-af82-f18e6408182b",
      "metadata": {
        "height": 31,
        "id": "adccca48-787e-4219-af82-f18e6408182b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c816827-e5b7-480a-826b-0ca715faca3c",
      "metadata": {
        "height": 31,
        "id": "5c816827-e5b7-480a-826b-0ca715faca3c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e6d608-c205-4141-bab8-0304dd910978",
      "metadata": {
        "height": 31,
        "id": "15e6d608-c205-4141-bab8-0304dd910978"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfc490d-090d-4e1c-b8ee-bf40ec4da4c3",
      "metadata": {
        "height": 31,
        "id": "abfc490d-090d-4e1c-b8ee-bf40ec4da4c3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0",
      "metadata": {
        "height": 31,
        "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}