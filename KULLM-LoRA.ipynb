{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT_Ochestration/blob/main/KULLM-LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch transformers tokenizers accelerate"
      ],
      "metadata": {
        "id": "gQk_dogLW5XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# git clone 에러 방지용\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "DKs2fM2XYfX5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nlpai-lab/KULLM.git"
      ],
      "metadata": {
        "id": "awoDHvMaYk57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KULLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e2u739MYwLT",
        "outputId": "e297a8af-f01a-442e-b613-9d0f88a652a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KULLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "from utils.prompter import Prompter\n",
        "\n",
        "MODEL = \"nlpai-lab/kullm-polyglot-5.8b-v2\""
      ],
      "metadata": {
        "id": "HizFrWryXNnP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL,\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True,\n",
        ").to(device=f\"cuda\", non_blocking=True)\n",
        "model.eval()\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=MODEL, device=0)\n",
        "\n",
        "prompter = Prompter(\"kullm\")\n",
        "\n",
        "\n",
        "def infer(instruction=\"\", input_text=\"\"):\n",
        "    prompt = prompter.generate_prompt(instruction, input_text)\n",
        "    output = pipe(prompt, max_length=512, temperature=0.2, num_beams=5, eos_token_id=2)\n",
        "    s = output[0][\"generated_text\"]\n",
        "    result = prompter.get_response(s)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "-I9vwvBjW5Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = infer(input_text=\"오늘 날씨는?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb5xhRU_ash5",
        "outputId": "9e3d4a82-055b-4bee-fae3-497ea132e626"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "죄송하지만 저는 AI 언어 모델이기 때문에 실시간 날씨 정보에 액세스할 수 없습니다. 날씨에 대한 최신 정보를 확인하려면 날씨 웹사이트나 앱을 방문하는 것이 좋습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = infer(input_text=\"회계 분개 입력에 대해 알려줘\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "epShNX4UW5Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZk1PZ3zW5OB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kdUokxpTW5LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B7R-KOmbW5IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QSA0kqd7W5Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bM5fK109W5BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1z-jRCcPwxd",
        "outputId": "368b35cc-c711-4319-a379-9254b3b33e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'chat-your-data'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 62 (delta 17), reused 15 (delta 13), pack-reused 34\u001b[K\n",
            "Receiving objects: 100% (62/62), 24.22 MiB | 3.42 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hwchase17/chat-your-data.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcG9TQjkQYZ1",
        "outputId": "02ea7169-1a02-4f50-eb8a-c2b3a0d6f7ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/chat-your-data\n"
          ]
        }
      ],
      "source": [
        "%cd chat-your-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_70Fh5LQdfl"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCRvoEL4Qjy0",
        "outputId": "60e73db1-7198-4394-af01-b00aab4bf11d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm8QsKVZQjvx",
        "outputId": "01a03ef2-252d-4e29-efcf-95c1f95f59ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "Splitting text...\n",
            "Creating vectorstore...\n"
          ]
        }
      ],
      "source": [
        "!python ingest_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYPGT-AURF8J"
      },
      "outputs": [],
      "source": [
        "!export share=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljele1L4Qjss",
        "outputId": "070165b4-45d6-459a-9ae3-ececc2aed0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/app.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python app.py --share=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GA6Yxwr9Qjpt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PSySN-0BQjmH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9Bjskm2dQjWj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yLaVoMHI-81w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BNBXldPD-8mE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMD2QEsavO1OTXQsO2xJ3Sy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}